

\section{Overall structure of \texttt{tspnng.py}}

The \texttt{tspnng.py} file at a high level divided into the following chunks, 
each of which is expanded upon in the coming sections. The \texttt{main.py} file used to run the \texttt{main()} function
from the command-line is more of a  scratchpad for testing the functions in this file, and later pointing the 
main to the appropriate test harnesses inside the \texttt{tspnng.py} file. Hence \texttt{main.py} will be developed 
independently of this document for convenience because it will be subject to continuous changes. .  

<<tspnng.py>>=

<<Headers>>
<<Data Generation>>
<<Generic utility classes and functions>>
<<Functions for plotting and interacting>>
<<Functions for generating various graphs>>
<<Functions dealing with intersecting two geometric graphs>>
<<Testing hypotheses>>
@


<<Headers>>=
import matplotlib.pyplot as plt
import matplotlib as mpl
from matplotlib import rc
rc('font',**{'family':'serif','serif':['Palatino']})
rc('text', usetex=True)

import scipy as sp
import numpy as np
import random
import networkx as nx

from sklearn.cluster import KMeans
import argparse, os, sys, time
from colorama import init, Fore, Style, Back
init() # this line does nothing on Linux/Mac,
       # but is important for Windows to display
       # colored text. See https://pypi.org/project/colorama/
import yaml
@


\section{Data Generation}

<<Data Generation>>=
<<TSPLIB data>>
<<Synthetic data>>
@

\subsection{TSPLIB data-sets}

\autoref{fig:tsplib} is a screenshot of the entire opening page of \cite{reinelt1991tsplib}
that should more than suffice as an intro to this popular set of benchmarks for various TSP-like problems. \footnote{Prof. Sandor Fekete has a much larger collection of interesting TSP data-sets, I believe?}

\begin{figure}[htbp]
  \centering
  \includegraphics[width=9.4cm]{miscimages/tsplib-screenshot.pdf}
  \caption{\label{fig:tsplib} Screenshot of the opening page of \cite{reinelt1991tsplib} }
\end{figure}

In this document we will be interested in that subset of instances corresponding to the Symmetric TSP with the standard 
Euclidean Metric. Pages 9 through 11 of \cite{reinelt1991tsplib} contain 4-column tables with all Symmetric TSP instances. 
We will be focusing precisely on those instances which have their 3rd column marked ``\verb|EUC_2D|''.  

The entire symmetric TSP data-set has been downloaded into the 

\begin{displayquote}
\texttt{./sym-tsp-tsplib/instances/sym-tsp-tsplib/instances/tsplib\_symmetric\_tsp\_instances/} 
\end{displayquote}

directory. 
After writing a small Python script \footnote{\texttt{tsplib\_to\_yaml.py} in that same directory} the subset of \verb|EUC_2D| instances
were converted into the convenient YAML format and copied into the 

\begin{displayquote}
\color{blue}
\texttt{./sym-tsp-tsplib/instances/sym-tsp-tsplib/instances/euclidean\_instances\_yaml/} 
\end{displayquote}
directory. \textit{\textbf{Unless otherwise noted, we will retrict our attention to this directory when talking about TSPLIB data.}}

To see what the point-sets look like peep into the folder \verb|tsplib_euc2d_pictures_of_instances| contained in the top level directory of the code. 
Note that the numbers affixed to each instance name indicate the number of points in that instance. See \autoref{fig:tsplibinstances} for some examples. 

This chunk implements two functions: the first one returns the full path names of each of the Euclidean instances in an list and  the second one
reads in a TSPLIB instance (identified by its file-name e.g. \verb|'berlin52.yml'|) in the \verb|euclidean_instances_yaml| directory 
and returns a list of 2D points for that instance. 

<<TSPLIB data>>=

def get_names_of_all_euclidean2D_instances(dirpath=\
         "./sym-tsp-tsplib/instances/euclidean_instances_yaml/" ):
     
     inst_names = []
     for name in os.listdir(dirpath):
         full_path = os.path.join(dirpath, name)
         if os.path.isfile(full_path):
             inst_names.append(name)
     return inst_names

def tsplib_instance_points(instance_file_name,\
                           dirpath="./sym-tsp-tsplib/instances/euclidean_instances_yaml/"):

        print(Fore.GREEN+"Reading " + instance_file_name, Style.RESET_ALL)
        with open(dirpath+instance_file_name) as file:
            data = yaml.load(file, Loader=yaml.FullLoader)
            points = np.asarray(data['points'])
        
        return points 
           
@


 \begin{figure}[htbp]
   \centering
   \includegraphics[width=7cm]{../tsplib_euc2d_pictures_of_instances/d493.png}
   \includegraphics[width=7cm]{../tsplib_euc2d_pictures_of_instances/d1655.png}
   \includegraphics[width=5cm]{../tsplib_euc2d_pictures_of_instances/d15112.png}
   \includegraphics[width=6cm]{../tsplib_euc2d_pictures_of_instances/pr2392.png}
   \caption{\label{fig:tsplibinstances} Instances of four TSPLIB data sets for the Symmetric TSP with 2D Euclidean Metric}
 \end{figure}



\subsection{Synthetic data-sets}
Alongside TSPLIB we will also be using synthetic data-sets i.e. uniform and non-uniform point-sets generated inside the unit-square $[0,1] \times [0,1]$. 
Note that each point is represented as a numpy array of size 2. 

This chunk generates uniform and non-uniform point sets in $[0,1] \times [0,1]$. To generate non-uniform point-sets we basically 
take a small set of uniformly distributed random points in the square, place a small square centered around each such random point and then
generate the appropriate number of points uniformly inside each of those squares. \footnote{A somewhat similar method was used in Jon Bentley's experimental TSP paper}
The size of the square is proportional to the distance of the sampled point from the boundary of the unit square. Thus you will often see tight clusters
near the boundary as you increase the number of input points (\texttt{`numpts`}). This was done to make sure all points get generated in the unit square. 
This would make it convenient for the purposes of plotting. Other non-uniform point-generation schemes will later be considered depending on which 
direction our investigation proceeds. 


<<Synthetic data>>=
def uniform_points(numpts):
     return  sp.rand(numpts, 2).tolist()

def non_uniform_points(numpts):

    cluster_size = int(np.sqrt(numpts)) 
    numcenters   = cluster_size
    centers      = sp.rand(numcenters,2).tolist()
    scale, points = 4.0, []

    for c in centers:
        cx, cy = c[0], c[1]
        sq_size      = min(cx,1-cx,cy, 1-cy)

        loc_pts_x    = np.random.uniform(low  = cx-sq_size/scale, 
                                         high = cx+sq_size/scale, 
                                         size = (cluster_size,))
        loc_pts_y    = np.random.uniform(low = cy-sq_size/scale, 
                                         high = cy+sq_size/scale, 
                                         size = (cluster_size,))

        points.extend(zip(loc_pts_x, loc_pts_y))

    num_remaining_pts = numpts - cluster_size * numcenters
    remaining_pts = sp.rand(num_remaining_pts, 2).tolist()
    points.extend(remaining_pts)
    return points
@

\section{Data Storage}
YAML\cite{ben2009yaml} is a convenient serialization and data-interchange format that we will be using 
for serializing output data of different experiments onto disk. Python has particularly good libraries for dealing with YAML. Basically, 
YAML records data in a format similar to a Python dictionary. Infact the \texttt{yaml} module provides a function that
transparently encodes any (appropriate) Python dictionary into a YAML file. In the function below, the 
\texttt{data} argument is a dictionary, and \texttt{dir\_name} and \texttt{file\_name} are strings. 
 
<<Generic utility classes and functions>>=
def write_to_yaml_file(data, dir_name, file_name):
   with open(dir_name + '/' + file_name, 'w') as outfile:
          yaml.dump( data, outfile, default_flow_style = False)
@


\section{Setting up TSPNNGInput class}

The following class is used to keep track of the points inserted thus far, along with 
any other auxiliary information. It basically functions as a convenience wrapper class around 
the main input data (basically a bunch of points in $\RR^2$) and a wrapper function around 
various graph generators such as TSP, Delaunary, $k\text{-}$NNG etc. 

<<Generic utility classes and functions>>=
class TSPNNGInput:
      def __init__(self, points=[]):
          self.points            = points

      def clearAllStates (self):
          self.points = []

      def generate_geometric_graph(self,graph_code):
           pass
@

\section{Setting up the Interactive Canvas}
The following set of code blocks create an interactive matplotlib canvas onto which the user can insert points, and then 
run the appropriate algorithm to visualize the intersection of the TSP and various graphs. 

We first set up the run handler function (each ``run'' corresponds to a run of the code on a particular data-set generated synthetically)
by connecting the keyboard and mouse handlers to the canvas. 

<<Functions for plotting and interacting>>=
def run_handler():
    fig, ax =  plt.subplots()
    run = TSPNNGInput()
    
    ax.set_xlim([xlim[0], xlim[1]])
    ax.set_ylim([ylim[0], ylim[1]])
    ax.set_aspect(1.0)
    ax.set_xticks([])
    ax.set_yticks([])
      
    mouseClick   = wrapperEnterRunPointsHandler(fig,ax, run)
    fig.canvas.mpl_connect('button_press_event' , mouseClick )
      
    keyPress     = wrapperkeyPressHandler(fig,ax, run)
    fig.canvas.mpl_connect('key_press_event', keyPress   )
    plt.show()
@



There are two principal callback functions \verb|wrapperEnterRunPointshandler| and \verb|wrapperkeypresshandler| used in the code above. 
These encode the interaction between the mouse and keyboard to the matplotlib canvas. 

First we define the call back function for mouse-clicks. Double-clicking the left mouse button (denoted as ``button 1'' in the matplotlib world)
inserts a small circle patch representing a point. Note that each mouse click 
clears the canvas
and freshly draws the input point-set from scratch. 
This helps with modifying an existing input to check how solution changes. 

<<Functions for plotting and interacting>>=
xlim, ylim = [0,1], [0,1]
def wrapperEnterRunPointsHandler(fig, ax, run):
    def _enterPointsHandler(event):
        if event.name      == 'button_press_event'     and \
           (event.button   == 1)                       and \
            event.dblclick == True                     and \
            event.xdata  != None                       and \
            event.ydata  != None:

             newPoint = np.asarray([event.xdata, event.ydata])
             run.points.append( newPoint  )
             print("You inserted ", newPoint)

             patchSize  = (xlim[1]-xlim[0])/130.0
                   
             ax.clear()

             for pt in run.points:
                  ax.add_patch( mpl.patches.Circle( pt, radius = patchSize,
                                                    facecolor='blue', edgecolor='black'  ))

             ax.set_title('Points Inserted: ' + str(len(run.points)), \
                           fontdict={'fontsize':25})
             applyAxCorrection(ax)
             fig.canvas.draw()

    return _enterPointsHandler
@

Now a call-back function for keyboard. Pressing \verb|`i'| or \verb|`I'| on the keyboard further prompts the 
user to insert a 2 or 3 letter code to indicate which graph should span the points. 

<<Functions for plotting and interacting>>=
def wrapperkeyPressHandler(fig,ax, run): 
       def _keyPressHandler(event):
               if event.key in ['n', 'N', 'u', 'U']: 
                     <<Enter type of point set to generate>>                   
               elif event.key in ['t' or 'T']:
                     <<Compute TSP and find common edges with various spanning graphs>>
               elif event.key in ['i', 'I']:                     
                     <<Compute spanning graph>>    
               elif event.key in ['x', 'X']:
                     <<Clear all line segments from the canvas>>
               elif event.key in ['c', 'C']: 
                     <<Clear all states and the canvas>>
       return _keyPressHandler
@

We now elaborate on the chunks in \verb|wrapperkeypresshandler|, and implement the boring technicalities. You 
can skip ahead to the next sections, at this point, if you wish. 

First we compute the TSP and then print a table mentioning how many of its edges are common to other
standard graphs. See \url{https://pypi.org/project/prettytable/} for more information on the 
prettytable module used to output data to terminal. 


<<Headers>>=
from prettytable import PrettyTable
@


<<Compute TSP and find common edges with various spanning graphs>>=
tsp_graph = get_concorde_tsp_graph(run.points)
graph_fns = [(get_delaunay_tri_graph, 'Delaunay Triangulation'), \
             (get_mst_graph         , 'Minimum Spanning Tree'), \
             (get_onion_graph       , 'Onion') ]

tbl             = PrettyTable()
tbl.field_names = ["Spanning Graph (G)", "G", "G \cap T", "T", "(G \cap T)/T"]

num_tsp_edges = len(tsp_graph.edges)
for ctr, (fn_body, fn_name) in zip(range(1,1+len(graph_fns)), graph_fns):
     geometric_graph = fn_body(run.points)
     num_graph_edges = len(geometric_graph.edges)
     common_edges    = list_common_edges(tsp_graph, geometric_graph)
     num_common_edges_with_tsp = len(common_edges)

     tbl.add_row([fn_name,                   \
                num_graph_edges,           \
                num_common_edges_with_tsp, \
                num_tsp_edges,             \
                "{perc:3.2f}".format(perc=1e2*num_common_edges_with_tsp/num_tsp_edges)+ ' %' ])
print(tbl)
render_graph(tsp_graph,fig,ax)
fig.canvas.draw()
@

In a kind of ``dual'' demo, we now compute and render the various geometric graphs, and then mention how many 
edges each graph has in common with the TSP. Thus we can explore the intersection of the TSP with a graph
from the point-of-view of both the TSP and the graph. 

The user should type the code enclosed in the brackets (e.g. `\verb|dt|' for delaunay triangulation) to generate the 
indicated graph that spans the points. 

<<Compute spanning graph>>=
algo_str = input(Fore.YELLOW + "Enter code for the graph you need to span the points:\n" + Style.RESET_ALL  +\
                     "(knng)   k-Nearest Neighbor Graph        \n"            +\
                     "(mst)    Minimum Spanning Tree           \n"            +\
                     "(onion)  Onion                           \n"            +\
                     "(dt)     Delaunay Triangulation         \n"             +\
                     "(conc)   TSP computed by the Concorde TSP library \n" +
                     "(pytsp)  TSP computed by the pure Python TSP library \n")
algo_str = algo_str.lstrip()

if algo_str == 'knng':
      k_str = input('===> What value of k do you want? ')
      k     = int(k_str)
      geometric_graph = get_knng_graph(run.points,k)

elif algo_str == 'mst':
     geometric_graph = get_mst_graph(run.points)

elif algo_str == 'onion':
     geometric_graph = get_onion_graph(run.points)

elif algo_str == 'dt':
      geometric_graph = get_delaunay_tri_graph(run.points)

elif algo_str == 'conc':
     geometric_graph = get_concorde_tsp_graph(run.points)

elif algo_str == 'pytsp':
     geometric_graph = get_py_tsp_graph(run.points)

else:
      print(Fore.YELLOW, "I did not recognize that option.", Style.RESET_ALL)
      geometric_graph = None

common_edges = list_common_edges(get_concorde_tsp_graph(run.points), geometric_graph)
print("------------------------------------------------------------------------------")
print("Number of edges in " + algo_str + " graph (TOTAL)                          :", len(geometric_graph.edges))
print("Number of edges in " + algo_str + " graph which are also in Concorde TSP   :", len(common_edges))
print("------------------------------------------------------------------------------", Style.RESET_ALL)



ax.set_title("Graph Type: " + geometric_graph.graph['type'] + '\n Number of nodes: ' + str(len(run.points)), fontdict={'fontsize':25})
render_graph(geometric_graph,fig,ax)
fig.canvas.draw()
@

If you want to enter a uniformly or non-uniformly distributed point-set in the unit-square press \verb|`u`| or \verb|`n`|
respectively after being prompted. 

<<Enter type of point set to generate>>=
numpts = int(input("\nHow many points should I generate?: ")) 
run.clearAllStates()
ax.cla()
applyAxCorrection(ax)

ax.set_xticks([])
ax.set_yticks([])
fig.texts = []
                 
if event.key in ['n', 'N']: 
        run.points = non_uniform_points(numpts)
else : 
        run.points = uniform_points(numpts)

patchSize  = (xlim[1]-xlim[0])/140.0

for site in run.points:      
    ax.add_patch(mpl.patches.Circle(site, radius = patchSize, \
                 facecolor='blue',edgecolor='black' ))

ax.set_title('Points generated: ' + str(len(run.points)), fontdict={'fontsize':25})
fig.canvas.draw()
@



Sometimes, you just want to clear the edges of the network from the graph, so that
a new graph can be rendered in its place on the points. For that, you need to press
`x` or `X`. 

<<Clear all line segments from the canvas>>=
print(Fore.GREEN, 'Removing network edges from canvas' ,Style.RESET_ALL)
ax.lines=[]
applyAxCorrection(ax)
fig.canvas.draw()
@

If you want to wipe the canvas and the point-cloud data (and everything else \ldots) clean, 
then press \verb|`c`|. 

<<Clear all states and the canvas>>=
run.clearAllStates()
ax.cla()
                                 
applyAxCorrection(ax)
ax.set_xticks([])
ax.set_yticks([])
                                    
fig.texts = []
fig.canvas.draw()
@





Often the \verb|ax| object has to be reset and cleaned of the various segment and circle patches, or even resetting the 
aspect ratio of the \verb|ax| object to be 1.0. These ``cleanup'' functions that were called in some of the code blocks above 
are implemented next. 

<<Functions for plotting and interacting>>=
def applyAxCorrection(ax):
      ax.set_xlim([xlim[0], xlim[1]])
      ax.set_ylim([ylim[0], ylim[1]])
      ax.set_aspect(1.0)

def clearPatches(ax):
    for index , patch in zip(range(len(ax.patches)), ax.patches):
        if isinstance(patch, mpl.patches.Polygon) == True:
            patch.remove()
    ax.lines[:]=[]
    applyAxCorrection(ax)

def clearAxPolygonPatches(ax):

    for index , patch in zip(range(len(ax.patches)), ax.patches):
        if isinstance(patch, mpl.patches.Polygon) == True:
            patch.remove()
    ax.lines[:]=[]
    applyAxCorrection(ax)
@


\section{Generating various geometric graphs}

For manipulating abstract graphs we use the NetworkX \cite{hagberg2008exploring} \footnote{already available inside the Anaconda Python distribution by default}. 
This section deals with generating the various geometric graphs using packages like Scipy and Sklearn and then converting them into a NetworkX graph
with the necessary edge and node attributes. Note that all the nodes in the abstract constructed below have the same numbering across all grap have the same 
numbering across all graphs: namely, the order in which the points occur in the \verb|points| array argument. 


\subsection{$k\text{-}$NNG}

\definecolor{bisque}{rgb}{1.0, 0.89, 0.77}
\renewcommand\fbox{\fcolorbox{bisque}{white}}
\setlength\fboxrule{0.1pt}

\begin{figure}[ht]
  \centering
  \fbox{\includegraphics[width=5cm]{./miscimages/1nng-example.png}} \hfill
  \fbox{\includegraphics[width=5cm]{./miscimages/2nng-example.png}} \hfill
  \fbox{\includegraphics[width=5cm]{./miscimages/3nng-example.png}}
  \caption{\label{fig:knng} Generating the $k$-NNG graphs with Scikit-Learn for various value of $k$ on the same set of 30 randomly generated points. Note that we are considering these graphs as undirected.}
\end{figure}


We use the nearest neighbor routine from the Scikit-learn \cite{pedregosa2011scikit} library. The documentation
for the various nearest neighor methods implemented therein can be found at 
\url{https://bit.ly/3nTQkqV}. Note that for the nearest-neighbor function of sklearn the $k\text{-}$ nearest-neighbors of a point
includes the point itself. Thus we use $(k+1)$ in the argument to the \verb|NearestNeighbors| function below, and take the last $k$
elements in the list returned --- the neighbors of a point are reported by that function in increasing order of distance from that point. 

<<Functions for generating various graphs>>=
def get_knng_graph(points,k):
     from sklearn.neighbors import NearestNeighbors
     points     = np.array(points)
     coords     = [{"coods":pt} for pt in points]
     knng_graph = nx.Graph()
     knng_graph.add_nodes_from(zip(range(len(points)), coords))
     nbrs = NearestNeighbors(n_neighbors=(k+1), algorithm='ball_tree').fit(points)
     distances, indices = nbrs.kneighbors(points)
     edge_list = []

     for nbidxs in indices:
          nfix = nbidxs[0]
          edge_list.extend([(nfix,nvar) for nvar in nbidxs[1:]])

     knng_graph.add_edges_from(  edge_list  )
     knng_graph.graph['type']   = str(k)+'nng'
     knng_graph.graph['weight'] =  None # TODO, also edge weights for each edge!!!
     return knng_graph
@


\subsection{Delaunay Triangulation}

\begin{figure}[ht]
  \centering
  \includegraphics[width=7cm]{./miscimages/dt-example.png}
  \caption{\label{fig:dt} Example of a Delaunay Triangulation computed by SciPy on 30 randomly generated points}
\end{figure}


We use the  \href{https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.Delaunay.html}{blackbox routine} 
for computing this graph implmeneted in Scipy \cite{virtanen2020scipy}. 

<<Functions for generating various graphs>>=
def get_delaunay_tri_graph(points):
     from scipy.spatial import Delaunay
     points       = np.array(points)
     coords       = [{"coods":pt} for pt in points]
     tri          = Delaunay(points)
     deltri_graph = nx.Graph()

     deltri_graph.add_nodes_from(zip(range(len(points)), coords))

     edge_list = []
     for (i,j,k) in tri.simplices:
         edge_list.extend([(i,j),(j,k),(k,i)])    
     deltri_graph.add_edges_from(  edge_list  )
     
     total_weight_of_edges = 0.0
     for edge in deltri_graph.edges:
           n1, n2 = edge
           pt1 = deltri_graph.nodes[n1]['coods'] 
           pt2 = deltri_graph.nodes[n2]['coods']
           edge_wt = np.linalg.norm(pt1-pt2)

           deltri_graph.edges[n1,n2]['weight'] = edge_wt
           total_weight_of_edges = total_weight_of_edges + edge_wt 
     
     deltri_graph.graph['weight'] = total_weight_of_edges
     deltri_graph.graph['type']   = 'dt'

     return deltri_graph
@


\subsection{Minimum Spanning Tree}

\begin{figure}[ht]
  \centering
  \includegraphics[width=6cm]{./miscimages/mst-example.png}
  \caption{\label{fig:mst} Example of a Minimum Spanning Tree computed by NetworkX on 30 randomly generated points}
\end{figure}


From elementary CG, we know that the MST of a set of points in the plane is a subset of the delaunay triangulation. Thus to compute the MST,
it suffices to compute the MST of the corresponding delaunay triangulation. 
See \href{https://networkx.github.io/documentation/stable/reference/algorithms/generated/networkx.algorithms.tree.mst.minimum_spanning_edges.html}{this page}
for a documentation of the code in NetworkX used to compute the MST on an abstract weighted undirected graph. Note that along with the Kruskal method (used below), both Prim's and Boruvka's 
algorithms have also been implemented in that library. 

<<Functions for generating various graphs>>=

def get_mst_graph(points):

     points = np.array(points)
     deltri_graph = get_delaunay_tri_graph(points)
     mst_graph = nx.algorithms.tree.mst.minimum_spanning_tree(deltri_graph, \
                                                              algorithm='kruskal')
     mst_graph.graph['type']   = 'mst'
     return mst_graph
@


\subsection{The Onion}

\begin{figure}[H]
  \centering
  \includegraphics[width=6cm]{./miscimages/onion-example.png}
  \caption{\label{fig:onion} Example of the Onion graph computed with computed with QHull (through SciPy) on 30 randomly generated points }
\end{figure}



Here we compute successive convex-hull of the point-set: compute the convex hull of the points, delete the hull points, 
compute the convex hull of this smaller point-set, repeating this process till we run out of points. 

The resulting sequence of convex layers form a graph called the onion. 

<<Functions for generating various graphs>>=

def get_onion_graph(points):
     from scipy.spatial import ConvexHull
     points      = np.asarray(points)     
     points_tmp  = points.copy()
     numpts      = len(points)
     onion_graph = nx.Graph()
     numpts_proc = -1

     << Definition of \verb|circular_edge_zip|>>
     while len(points_tmp) >= 3:
           <<Generate convex hull of points remaining in \verb|points_tmp|>>
           <<Update \verb|onion_graph|>>
           <<Remove points reported in the convex hull from \verb|points_tmp|>>

     if len(points_tmp) == 2:
          <<Join two remaining points by an edge in \verb|onion_graph|>>
     elif len(points_tmp) == 1:
          <<Add the remaining points as a node in \verb|onion_graph|>>
 
     onion_graph.graph['type'] = 'onion'
     return onion_graph
@


Note that the convex hull is computed by Scipy using the Qhull library as mentioned in the \href{https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.ConvexHull.html}{docs}. 
<<Generate convex hull of points remaining in \verb|points_tmp|>>=
hull            = ConvexHull(points_tmp)
pts_on_hull     = [points_tmp[i] for i in hull.vertices]
coords          = [{"coods":pt} for pt in pts_on_hull]
@


<<Update \verb|onion_graph|>>=
new_node_idxs   = range(numpts_proc+1, numpts_proc+len(hull.vertices)+1)
onion_graph.add_nodes_from(zip(new_node_idxs, coords))
onion_graph.add_edges_from(circular_edge_zip(new_node_idxs))
@


Given a set of node ids of a graph provided as a list of 
integers, the following function, returns a cycle of edges with successive nodes joined in
the order provided. e.g. $[1,2,3] \rarr [(1,2),(2,3),(3,1)]$. Convenient to have this defined 
separately. 

<< Definition of \verb|circular_edge_zip|>>=
def circular_edge_zip(xs):
    xs = list(xs) # in the event that xs is of the zip or range type 
    if len(xs) in [0,1] :
         zipl = []
    elif len(xs) == 2 :
         zipl = [(xs[0],xs[1])]
    else:
         zipl = list(zip(xs,xs[1:]+xs[:1]))
    return zipl

@




<<Remove points reported in the convex hull from \verb|points_tmp|>>=
numpts_proc  = numpts_proc + len(hull.vertices)
rem_pts_idxs = list(set(range(len(points_tmp)))-set(hull.vertices)) 
points_tmp   = [ points_tmp[idx] for idx in rem_pts_idxs ]
coords       = [{"coods":pt} for pt in points]
@


There are two edge cases: when only two points and one point remain. These cases, cannot be handled by Qhull (It reports an error at the terminal,
saying it needs at least three points must be provided as input). Hence the separate treatment in the following two chunks. 


When two nodes, remain, we just join them by an edge. 

<<Join two remaining points by an edge in \verb|onion_graph|>>=
p, l = numpts_proc+1, numpts_proc+2
onion_graph.add_node(p)
onion_graph.add_node(l)
onion_graph.nodes[p]['coods'] = points_tmp[0]
onion_graph.nodes[l]['coods'] = points_tmp[1]
onion_graph.add_edge(p,l)
@

No edges to add here, just the node. 

<<Add the remaining points as a node in \verb|onion_graph|>>=
l = numpts_proc+1 
onion_graph.add_node(l)
onion_graph.nodes[l]['cood'] = points_tmp[0]
@




\subsection{Traveling Saleman Tour (Cycle)}

\begin{figure}[ht]
  \centering
  \includegraphics[width=6cm]{./miscimages/conc-example.png}
  \caption{\label{fig:tsp} Example of an \underline{optimal} TSP tour computed with Concorde  on 30 randomly generated points }
\end{figure}


We use two separate independent routines that each compute the TSP. One is the 
\verb|tsp| module available at \link{https://pypi.org/project/tsp/}
the other being, Concorde, through its Python interface (whose github page can be accessed at 
\link{https://github.com/jvkersch/pyconcorde}. Anedoctally speaking the first solver works relatively 
quickly on point-sets upto size 30. Because of its simplicity, we used it in the intial stages of writing
this report. It is clearly not competitive with Concorde (which can solve a 300 size instances in a couple of seconds), 
but it serves as a useful backup routine, in the event that a machine faces problems with the installation of PyConcorde.

\subsubsection{* Using the \texttt{tsp} library}
<<Functions for generating various graphs>>=
def get_py_tsp_graph(points):
     import tsp
     points = np.array(points)
     coords = [{"coods":pt} for pt in points]
     <<Generate TSP cycle and convert into NetworkX graph>>
     <<Compute weight of each edge and total edge weight>>
     <<Set graph attributes>>     
     return tsp_graph
@


<<Generate TSP cycle and convert into NetworkX graph>>=
t              = tsp.tsp(points)
idxs_along_tsp = t[1]
tsp_graph      = nx.Graph()

tsp_graph.add_nodes_from(zip(range(len(points)), coords))
edge_list = list(zip(idxs_along_tsp, idxs_along_tsp[1:])) + \
                  [(idxs_along_tsp[-1],idxs_along_tsp[0])]
tsp_graph.add_edges_from(  edge_list  )
@


<<Compute weight of each edge and total edge weight>>=
total_weight_of_edges = 0.0
for edge in tsp_graph.edges:

      n1, n2 = edge
      pt1 = tsp_graph.nodes[n1]['coods'] 
      pt2 = tsp_graph.nodes[n2]['coods']
      edge_wt = np.linalg.norm(pt1-pt2)

      tsp_graph.edges[n1,n2]['weight'] = edge_wt
      total_weight_of_edges = total_weight_of_edges + edge_wt 
@

<<Set graph attributes>>=
tsp_graph.graph['weight'] = total_weight_of_edges
tsp_graph.graph['type']   = 'pytsp'
@


\subsubsection{* Using the Pyconcorde library}

This library is a thin interface around Concorde. Installing Pyconcorde
automatically installs Concorde and other required libraries such as QSOpt. 
Instructions for installation are given in Appendix I.  

Note that for the \verb|EUC_2D| cases, the Concorde solver works only on points with integer coordinates. 
Since our synthetic data-sets will be generated inside the unit-square, we scale by the amount \verb|scale_factor| and then 
rounded to an integer using \verb|int()|. For a sufficiently large value \verb|scaling_factor|,  
ordering of points reported by Concorde should be the same as  if the algorithm was run on the 
unscaled points. 

Note that Concorde crashes when you pass it only three points. Probably something to do with
its internals. Of course for the case of one or two points, the package explcitly informs us that we must pass
a longer list. 

<<Functions for generating various graphs>>=
def get_concorde_tsp_graph(points, scaling_factor=1000):
     from concorde.tsp import TSPSolver
     points = np.array(points)
     coords = [{"coods":pt} for pt in points]

     xs = [int(scaling_factor*pt[0]) for pt in points]
     ys = [int(scaling_factor*pt[1]) for pt in points]
     solver = TSPSolver.from_data(xs, ys, norm='EUC_2D', name=None)
     print(Fore.GREEN)
     solution = solver.solve()
     print(Style.RESET_ALL)

     concorde_tsp_graph=nx.Graph()
          
     idxs_along_tsp = solution.tour
     concorde_tsp_graph.add_nodes_from(zip(range(len(points)), coords))
     edge_list = list(zip(idxs_along_tsp, idxs_along_tsp[1:])) + \
                    [(idxs_along_tsp[-1],idxs_along_tsp[0])]
     concorde_tsp_graph.add_edges_from(  edge_list  )

     concorde_tsp_graph.graph['type']   = 'conc'
     concorde_tsp_graph.graph['found_tour_p'] = solution.found_tour
     concorde_tsp_graph.graph['weight'] = None ### TODO!! 
     return concorde_tsp_graph
@



\subsection{Graph Powers}



\section{Rendering the graphs}

For this we just draw each edge of the geometric graph as a straight line segment 
between the points( each of which happens to be a node of the graph). 

For the special case of the TSP, we render it as a polygon patch, because the interior
needs to be colored. 
<<Functions for plotting and interacting>>=
def render_graph(G,fig,ax):
     if G is None:
            return
     <<Set up edge colors depending on graph type>>
     if G.graph['type'] not in ['conc', 'pytsp']:
          <<Iterate through graph edges and draw as segments>>
     else:
          <<Draw tour as polygon patch>>
          
     ax.axis('off') # turn off box surrounding plot
     fig.canvas.draw()
@

<<Set up edge colors depending on graph type>>=
edgecol = None
if G.graph['type'] == 'mst':
     edgecol = 'g'
elif G.graph['type'] == 'onion':
     edgecol = 'gray'
elif G.graph['type'] in ['conc','pytsp']:
     edgecol = 'r'
elif G.graph['type'] == 'dt':
     edgecol = 'b'
elif G.graph['type'][-3:] == 'nng':
     edgecol = 'm'
@


<<Iterate through graph edges and draw as segments>>=

for elt in list(G.nodes(data=True)):
     print(elt)

for  (nidx1, nidx2) in G.edges:
    x1, y1 = G.nodes[nidx1]['coods']
    x2, y2 = G.nodes[nidx2]['coods']
    ax.plot([x1,x2],[y1,y2],'-', color=edgecol)
@

Because the \textit{interior} of the tour has to be colored, we render it as a polygon patch, and not
just as a bunch of edges. Since I've stored the tour as a generic graph, 
the \verb|.edges| data member of such a container, does not necessarily report 
the edges in the order encountered along the TSP. 

But this order can trivially be extracted using depth first search. 

<<Draw tour as polygon patch>>=
from networkx.algorithms.traversal.depth_first_search import dfs_edges
node_coods = []
for (nidx1, nidx2) in dfs_edges(G):
       node_coods.append(G.nodes[nidx1]['coods'])
       node_coods.append(G.nodes[nidx2]['coods'])

node_coods = np.asarray(node_coods)
from matplotlib.patches import Polygon
from matplotlib.collections import PatchCollection

polygon = Polygon(node_coods, closed=True, \
                  facecolor=(255/255, 255/255, 102/255,0.5), \
                  edgecolor='k', linewidth=1)
ax.add_patch(polygon)
@



\section{Finding common edges between two graphs}


It is possible the same edge may exist in both the graphs
but the indices recorded in the nodes may be in a different order. 
Hence, we explicitly define edges from two different graphs on the same set of nodes
as being equal, if they are equal as sorted lists.

<<Functions dealing with intersecting two geometric graphs>>=
def edge_equal_p(e1,e2):
     e1 = sorted(list(e1))
     e2 = sorted(list(e2))
     return (e1==e2)
@

To find the set of edges common to two graphs on the same set of nodes, we take take each
edge from one of the graphs and check whether it exists in the other. 


<<Functions dealing with intersecting two geometric graphs>>=
def list_common_edges(g1, g2):
     common_edges = []
     for e1 in g1.edges:
          for e2 in g2.edges:
             if  edge_equal_p(e1,e2):
                  common_edges.append(e1)
     return common_edges
@

Finally, just a small function that tests if two graphs intersect. 

<<Functions dealing with intersecting two geometric graphs>>=
def graphs_intersect_p(g1,g2):
     flag = False
     if list_common_edges(g1,g2):     
          flag = True 
     return flag
@

\section{Hypothesis testing!}

<<Testing hypotheses>>=
@



